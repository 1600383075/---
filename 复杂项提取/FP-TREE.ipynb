{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T02:34:32.959873Z",
     "start_time": "2020-06-12T02:34:30.797601Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conditional tree for: {'y'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       x   3\n",
      "conditional tree for: {'y', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "conditional tree for: {'s'}\n",
      "   Null Set   1\n",
      "     x   3\n",
      "conditional tree for: {'t'}\n",
      "   Null Set   1\n",
      "     y   3\n",
      "       z   3\n",
      "         x   3\n",
      "conditional tree for: {'z', 't'}\n",
      "   Null Set   1\n",
      "     y   3\n",
      "conditional tree for: {'t', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "       y   3\n",
      "conditional tree for: {'y', 't', 'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "conditional tree for: {'x'}\n",
      "   Null Set   1\n",
      "     z   3\n",
      "[{'r'}, {'y'}, {'y', 'z'}, {'y', 'x'}, {'y', 'z', 'x'}, {'s'}, {'s', 'x'}, {'t'}, {'y', 't'}, {'z', 't'}, {'z', 'y', 't'}, {'t', 'x'}, {'z', 't', 'x'}, {'y', 't', 'x'}, {'y', 'z', 't', 'x'}, {'x'}, {'z', 'x'}, {'z'}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    start_time = time()\\n    parse_dat = [line.split() for line in open('./machinelearninginaction/Ch12/kosarak.dat').readlines()]\\n    init_set = create_init_set(parse_dat)\\n    my_fp_tree, my_header_tab = create_tree(init_set, 100000)\\n    my_freq_list = []\\n    mine_tree(my_fp_tree, my_header_tab, 100000, set([]), my_freq_list)\\n    end_time = time()\\n    print('被10万或者更多人浏览过的新闻报道或报道集合数:', len(my_freq_list))\\n    print('被10万或者更多人浏览过的新闻报道或报道集合:', my_freq_list)\\n    print('总共执行时间:', end_time - start_time)\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import *\n",
    "from time import *\n",
    "\n",
    "\n",
    "def load_simple_data():\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        创建加载简单数据集\n",
    "    Parameters:\n",
    "        无\n",
    "    Returns:\n",
    "         simple_data - 简单数据集\n",
    "    Modify:\n",
    "        2018-12-27\n",
    "    \"\"\"\n",
    "    simple_data = [['r', 'z', 'h', 'j', 'p'],\n",
    "                   ['z', 'y', 'x', 'w', 'v', 'u', 't', 's'],\n",
    "                   ['z'],\n",
    "                   ['r', 'x', 'n', 'o', 's'],\n",
    "                   ['y', 'r', 'x', 'z', 'q', 't', 'p'],\n",
    "                   ['y', 'z', 'x', 'e', 'q', 's', 't', 'm']]\n",
    "    return simple_data\n",
    "\n",
    "\n",
    "def create_init_set(data_set):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        计算项集在数据集的出现次数\n",
    "    Parameters:\n",
    "        data_set - 数据集\n",
    "    Returns:\n",
    "         ret_dict - 包含出现次数的项集字典\n",
    "    Modify:\n",
    "        2018-12-27\n",
    "    \"\"\"\n",
    "    ret_dict = {}\n",
    "    for trans in data_set:\n",
    "        ret_dict[frozenset(trans)] = 1\n",
    "    return ret_dict\n",
    "\n",
    "\n",
    "def update_tree(items, in_tree, header_table, count):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        更新树节点，让FP树生长\n",
    "    Parameters:\n",
    "        items - 项集\n",
    "        in_tree - 当前FP树\n",
    "        header_table - 头指针表\n",
    "        count - 次数\n",
    "    Returns:\n",
    "         无\n",
    "    Modify:\n",
    "        2018-12-27\n",
    "    \"\"\"\n",
    "    # 判断排序后列表的第一个元素是否已经是根节点的子节点\n",
    "    if items[0] in in_tree.children:\n",
    "        # 添加出现次数\n",
    "        # children = {}\n",
    "        in_tree.children[items[0]].inc(count)\n",
    "    else:\n",
    "        # 创建根节点的子节点\n",
    "        in_tree.children[items[0]] = TreeNode(items[0], count, in_tree)\n",
    "        # 如果该元素的后继节点不存在，则直接加入。如果有后继节点，则遍历链表尾部将其加入\n",
    "        if header_table[items[0]][1] == None:\n",
    "            header_table[items[0]][1] = in_tree.children[items[0]]\n",
    "        else:\n",
    "            update_header(header_table[items[0]][1], in_tree.children[items[0]])\n",
    "    # 列表元素长度大于1，递归调用更新FP树函数\n",
    "    if len(items) > 1:\n",
    "        update_tree(items[1::], in_tree.children[items[0]], header_table, count)\n",
    "\n",
    "\n",
    "def update_header(node_to_test, target_node):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        更新头指针表的节点链接\n",
    "    Parameters:\n",
    "        node_to_test - 遍历节点\n",
    "        target_node - 目标节点\n",
    "    Returns:\n",
    "         无\n",
    "    Modify:\n",
    "        2018-12-27\n",
    "    \"\"\"\n",
    "    # 遍历到链表尾节点\n",
    "    while (node_to_test.node_link != None):\n",
    "        node_to_test = node_to_test.node_link\n",
    "    # 将刚添加的树节点加入链表的尾部\n",
    "    node_to_test.node_link = target_node\n",
    "\n",
    "\n",
    "def create_tree(data_set, min_sup=1):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        遍历数据集两次构建FP树\n",
    "    Parameters:\n",
    "        data_set - 包含项集出现次数的数据集字典\n",
    "        min_sup - 最小支持度\n",
    "    Returns:\n",
    "         ret_tree - FP树\n",
    "         hearder_table - 头指针表\n",
    "    Modify:\n",
    "        2018-12-27\n",
    "    \"\"\"\n",
    "    hearder_table = {}\n",
    "    # 第一次遍历数据集，获取单个元素的次数\n",
    "    for trans in data_set:\n",
    "        for item in trans:\n",
    "            hearder_table[item] = hearder_table.get(item, 0) + data_set[trans]\n",
    "    # 去除不满足最小支持度的单个元素\n",
    "    for k in list(hearder_table.keys()):\n",
    "        if hearder_table[k] < min_sup:\n",
    "            del (hearder_table[k])\n",
    "    freq_item_set = set(hearder_table.keys())\n",
    "    # 无频繁项就直接返回\n",
    "    if len(freq_item_set) == 0:\n",
    "        return None, None\n",
    "    # 扩展头指针表，添加指向每种类型第一个元素的指针（节点链接）\n",
    "    for k in hearder_table:\n",
    "        hearder_table[k] = [hearder_table[k], None]\n",
    "    # 创建根节点\n",
    "    ret_tree = TreeNode('Null Set', 1, None)\n",
    "    # 第二次遍历数据集，构建FP树\n",
    "    for tran_set, count in data_set.items():\n",
    "        # tran_set: frozenset({'h', 'p', 'z', 'j', 'r'})\n",
    "        # count: 1\n",
    "        local_d = {}\n",
    "        # 如果单个元素是频繁项，则加入localD列表\n",
    "        for item in tran_set:\n",
    "            if item in freq_item_set:\n",
    "                # hearder_table:{'b': [3, None]}\n",
    "                local_d[item] = hearder_table[item][0]\n",
    "        # localD: {'r': 3, 'j': 1, 'z': 5, 'h': 1, 'p': 2}\n",
    "        if len(local_d) > 0:\n",
    "            # 元素按出现次数排序\n",
    "            ordered_items = [v[0] for v in sorted(local_d.items(), key=lambda p: p[1], reverse=True)]\n",
    "            # 更新FP树，让FP树生长\n",
    "            update_tree(ordered_items, ret_tree, hearder_table, count)\n",
    "    return ret_tree, hearder_table\n",
    "\n",
    "\n",
    "class TreeNode:\n",
    "    # name：节点元素名称，在构造时初始化为给定值\n",
    "    # count：出现次数，在构造时初始化为给定值\n",
    "    # node_link：指向下一个相似节点的指针，默认为None\n",
    "    # parent：指向父节点的指针，在构造时初始化为给定值\n",
    "    # children：指向子节点的字典，以子节点的元素名称为键，指向子节点的指针为值，初始化为空字典\n",
    "    def __init__(self, name_value, num_occur, parent_node):\n",
    "        self.name = name_value\n",
    "        self.count = num_occur\n",
    "        self.node_link = None\n",
    "        self.parent = parent_node\n",
    "        self.children = {}\n",
    "\n",
    "    def inc(self, num_occur):\n",
    "        # 增加节点出现次数\n",
    "        self.count += num_occur\n",
    "\n",
    "    def disp(self, ind=1):\n",
    "        # 用于将树以文本形式显示\n",
    "        print('  ' * ind, self.name, ' ', self.count)\n",
    "        for child in self.children.values():\n",
    "            child.disp(ind + 1)\n",
    "\n",
    "\n",
    "def ascend_tree(leaf_node, prefix_path):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        根据当前节点向前追溯至根节点，记录前缀路径\n",
    "    Parameters:\n",
    "        leaf_node - 给定元素项节点\n",
    "        prefix_path - 前缀路径列表\n",
    "    Returns:\n",
    "         无\n",
    "    Modify:\n",
    "        2019-1-6\n",
    "    \"\"\"\n",
    "    # 如果节点有父节点，则将当前节点添加至前缀路径中，之后再递归向上追溯\n",
    "    if leaf_node.parent != None:\n",
    "        prefix_path.append(leaf_node.name)\n",
    "        ascend_tree(leaf_node.parent, prefix_path)\n",
    "\n",
    "\n",
    "def find_prefix_path(base_pat, tree_node):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        发现以给定元素项结尾的所有前缀路径\n",
    "    Parameters:\n",
    "        base_pat - 元素项\n",
    "        tree_node - 需遍历节点\n",
    "    Returns:\n",
    "         cond_pats - 所有条件模式基字典\n",
    "    Modify:\n",
    "        2019-1-6\n",
    "    \"\"\"\n",
    "    # 所有条件模式基字典\n",
    "    cond_pats = {}\n",
    "    # 遍历该节点的整个链表节点，记录每个节点的前缀路径，并将其添加至条件模式基当中\n",
    "    while tree_node != None:\n",
    "        prefix_path = []\n",
    "        ascend_tree(tree_node, prefix_path)\n",
    "        # 因为该节点也被加进了路径当中，所以需要路径的长度大于1\n",
    "        if len(prefix_path) > 1:\n",
    "            # 如果有前缀路径，则将前缀路径加入条件模式基集合中，并且将该元素在该前缀路径中出现的次数也添加进去\n",
    "            cond_pats[frozenset(prefix_path[1:])] = tree_node.count\n",
    "        # 当前节点的条件模式基查找完毕后，继续查找头指针链表中下一个节点的条件模式基\n",
    "        tree_node = tree_node.node_link\n",
    "    return cond_pats\n",
    "\n",
    "\n",
    "def mine_tree(in_tree, header_table, min_sup, pre_fix, freq_item_list):\n",
    "    \"\"\"\n",
    "    Function:\n",
    "        创建条件模式树\n",
    "    Parameters:\n",
    "        in_tree - FP树\n",
    "        header_table - 头指针表\n",
    "        min_sup - 最小支持度\n",
    "        pre_fix - 上一次递归的频繁项集合的前缀\n",
    "        freq_item_list - 频繁项集列表\n",
    "    Returns:\n",
    "        无\n",
    "    Modify:\n",
    "        2019-1-6\n",
    "    \"\"\"\n",
    "    # 对头指针表中的元素项按照其出现频率从小到大进行排序\n",
    "    big_l = [v[0] for v in sorted(header_table.items(), key=lambda p:p[1][0])]\n",
    "    # 遍历单元素频繁集\n",
    "    for base_pat in big_l:\n",
    "        new_freq_set = pre_fix.copy()\n",
    "        new_freq_set.add(base_pat)\n",
    "        freq_item_list.append(new_freq_set)\n",
    "        # 获得该元素的所有条件模式基，相当于一个事务集合\n",
    "        cond_patt_bases = find_prefix_path(base_pat, header_table[base_pat][1])\n",
    "        # 根据所有条件模式基集合来构建条件模式树\n",
    "        my_cond_tree, my_head = create_tree(cond_patt_bases, min_sup)\n",
    "        # 如果条件模式树的头指针表不空(每次建树时对元素支持度有要求\n",
    "        # 如果小于支持度则该元素不参与建树过程，所以在建树时，条件模式基中的元素会越来越少，最后会是空树)，则递归建树\n",
    "        if my_head != None:\n",
    "            print('conditional tree for:', new_freq_set)\n",
    "            my_cond_tree.disp(1)\n",
    "            mine_tree(my_cond_tree, my_head, min_sup, new_freq_set, freq_item_list)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # simple_data = load_simple_data()\n",
    "    # init_data = create_init_set(simple_data)\n",
    "    # print(simple_data)\n",
    "    # print(init_data)\n",
    "    '''\n",
    "    simple_data = load_simple_data()\n",
    "    init_data = create_init_set(simple_data)\n",
    "    my_fp_tree, my_header_tab = create_tree(init_data, 3)\n",
    "    my_fp_tree.disp()\n",
    "    ''' \n",
    "    '''\n",
    "    simple_data = load_simple_data()\n",
    "    init_data = create_init_set(simple_data)\n",
    "    my_fp_tree, my_header_tab = create_tree(init_data, 3)\n",
    "    cond_pats_1 = find_prefix_path('x', my_header_tab['x'][1])\n",
    "    print(cond_pats_1)\n",
    "    cond_pats_2 = find_prefix_path('z', my_header_tab['z'][1])\n",
    "    print(cond_pats_2)\n",
    "    cond_pats_3 = find_prefix_path('r', my_header_tab['r'][1])\n",
    "    print(cond_pats_3)\n",
    "    '''\n",
    "    simple_data = load_simple_data()\n",
    "    init_data = create_init_set(simple_data)\n",
    "    my_fp_tree, my_header_tab = create_tree(init_data, 3)\n",
    "    freq_items = []\n",
    "    mine_tree(my_fp_tree, my_header_tab, 3, set([]), freq_items)\n",
    "    print(freq_items)\n",
    "'''\n",
    "    start_time = time()\n",
    "    parse_dat = [line.split() for line in open('./machinelearninginaction/Ch12/kosarak.dat').readlines()]\n",
    "    init_set = create_init_set(parse_dat)\n",
    "    my_fp_tree, my_header_tab = create_tree(init_set, 100000)\n",
    "    my_freq_list = []\n",
    "    mine_tree(my_fp_tree, my_header_tab, 100000, set([]), my_freq_list)\n",
    "    end_time = time()\n",
    "    print('被10万或者更多人浏览过的新闻报道或报道集合数:', len(my_freq_list))\n",
    "    print('被10万或者更多人浏览过的新闻报道或报道集合:', my_freq_list)\n",
    "    print('总共执行时间:', end_time - start_time)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T02:34:35.029664Z",
     "start_time": "2020-06-12T02:34:34.990772Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frequent patterns:\n",
      "{frozenset({'bread'}): 3,\n",
      " frozenset({'milk', 'bread'}): 3,\n",
      " frozenset({'eggs'}): 3,\n",
      " frozenset({'milk', 'eggs'}): 3,\n",
      " frozenset({'bread', 'eggs'}): 3,\n",
      " frozenset({'milk'}): 4,\n",
      " frozenset({'milk', 'bread', 'eggs'}): 3,\n",
      " frozenset({'gloves'}): 3,\n",
      " frozenset({'socks'}): 4,\n",
      " frozenset({'gloves', 'socks'}): 3,\n",
      " frozenset({'shoes'}): 3,\n",
      " frozenset({'socks', 'shoes'}): 3}\n",
      "association rules:\n",
      "[(frozenset({'bread'}), frozenset({'milk'}), 1.0),\n",
      " (frozenset({'milk'}), frozenset({'bread'}), 0.75),\n",
      " (frozenset({'eggs'}), frozenset({'milk'}), 1.0),\n",
      " (frozenset({'milk'}), frozenset({'eggs'}), 0.75),\n",
      " (frozenset({'bread', 'eggs'}), frozenset({'milk'}), 1.0),\n",
      " (frozenset({'eggs'}), frozenset({'milk', 'bread'}), 1.0),\n",
      " (frozenset({'bread'}), frozenset({'milk', 'eggs'}), 1.0),\n",
      " (frozenset({'milk', 'eggs'}), frozenset({'bread'}), 1.0),\n",
      " (frozenset({'milk'}), frozenset({'bread', 'eggs'}), 0.75),\n",
      " (frozenset({'milk', 'bread'}), frozenset({'eggs'}), 1.0),\n",
      " (frozenset({'eggs'}), frozenset({'bread'}), 1.0),\n",
      " (frozenset({'bread'}), frozenset({'eggs'}), 1.0),\n",
      " (frozenset({'socks'}), frozenset({'gloves'}), 0.75),\n",
      " (frozenset({'gloves'}), frozenset({'socks'}), 1.0),\n",
      " (frozenset({'shoes'}), frozenset({'socks'}), 1.0),\n",
      " (frozenset({'socks'}), frozenset({'shoes'}), 0.75)]\n",
      "rules num: 16\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "   \n",
    "def loadDataSet():\n",
    "    dataSet = [['bread', 'milk', 'vegetable', 'fruit', 'eggs'],\n",
    "               ['noodle', 'beef', 'pork', 'water', 'socks', 'gloves', 'shoes', 'rice'],\n",
    "               ['socks', 'gloves'],\n",
    "               ['bread', 'milk', 'shoes', 'socks', 'eggs'],\n",
    "               ['socks', 'shoes', 'sweater', 'cap', 'milk', 'vegetable', 'gloves'],\n",
    "               ['eggs', 'bread', 'milk', 'fish', 'crab', 'shrimp', 'rice']]\n",
    "   \n",
    "    return dataSet\n",
    "   \n",
    "def transfer2FrozenDataSet(dataSet):\n",
    "    frozenDataSet = {}\n",
    "    for elem in dataSet:\n",
    "        frozenDataSet[frozenset(elem)] = 1\n",
    "   \n",
    "    return frozenDataSet\n",
    "   \n",
    "class TreeNode:\n",
    "    def __init__(self, nodeName, count, nodeParent):\n",
    "        self.nodeName = nodeName\n",
    "        self.count = count\n",
    "        self.nodeParent = nodeParent\n",
    "        self.nextSimilarItem = None\n",
    "        self.children = {}\n",
    "   \n",
    "    def increaseC(self, count):\n",
    "        self.count += count\n",
    "   \n",
    "   \n",
    "def createFPTree(frozenDataSet, minSupport):\n",
    "    # scan dataset at the first time, filter out items which are less than minSupport\n",
    "    headPointTable = {}\n",
    "    for items in frozenDataSet:\n",
    "        for item in items:\n",
    "            headPointTable[item] = headPointTable.get(item, 0) + frozenDataSet[items]\n",
    "    headPointTable = {\n",
    "        k: v\n",
    "        for k, v in headPointTable.items() if v >= minSupport\n",
    "    }\n",
    "    frequentItems = set(headPointTable.keys())\n",
    "    if len(frequentItems) == 0: return None, None\n",
    "   \n",
    "    for k in headPointTable:\n",
    "        headPointTable[k] = [headPointTable[k], None]\n",
    "   \n",
    "    fptree = TreeNode(\"null\", 1, None)\n",
    "    # scan dataset at the second time, filter out items for each record\n",
    "    for items, count in frozenDataSet.items():\n",
    "        frequentItemsInRecord = {}\n",
    "        for item in items:\n",
    "            if item in frequentItems:\n",
    "                frequentItemsInRecord[item] = headPointTable[item][0]\n",
    "        if len(frequentItemsInRecord) > 0:\n",
    "            frequentItemsInRecord = sorted(frequentItemsInRecord.items(), key=lambda v: v[0])\n",
    "            orderedFrequentItems = [v[0] for v in sorted(frequentItemsInRecord, key=lambda v: v[1], reverse=True)]\n",
    "            updateFPTree(fptree, orderedFrequentItems, headPointTable, count)\n",
    "   \n",
    "    return fptree, headPointTable\n",
    "   \n",
    "def updateFPTree(fptree, orderedFrequentItems, headPointTable, count):\n",
    "    # handle the first item\n",
    "    if orderedFrequentItems[0] in fptree.children:\n",
    "        fptree.children[orderedFrequentItems[0]].increaseC(count)\n",
    "    else:\n",
    "        fptree.children[orderedFrequentItems[0]] = TreeNode(orderedFrequentItems[0], count, fptree)\n",
    "   \n",
    "        # update headPointTable\n",
    "        if headPointTable[orderedFrequentItems[0]][1] == None:\n",
    "            headPointTable[orderedFrequentItems[0]][1] = fptree.children[orderedFrequentItems[0]]\n",
    "        else:\n",
    "            updateHeadPointTable(headPointTable[orderedFrequentItems[0]][1], fptree.children[orderedFrequentItems[0]])\n",
    "    # handle other items except the first item\n",
    "    if (len(orderedFrequentItems) > 1):\n",
    "        updateFPTree(fptree.children[orderedFrequentItems[0]], orderedFrequentItems[1::], headPointTable, count)\n",
    "   \n",
    "   \n",
    "def updateHeadPointTable(headPointBeginNode, targetNode):\n",
    "    while (headPointBeginNode.nextSimilarItem != None):\n",
    "        headPointBeginNode = headPointBeginNode.nextSimilarItem\n",
    "    headPointBeginNode.nextSimilarItem = targetNode\n",
    "   \n",
    "   \n",
    "def mineFPTree(headPointTable, prefix, frequentPatterns, minSupport):\n",
    "    # for each item in headPointTable, find conditional prefix path, create conditional fptree,\n",
    "    # then iterate until there is only one element in conditional fptree\n",
    "    headPointItems = [v[0] for v in sorted(headPointTable.items(), key=lambda v: v[1][0])]\n",
    "    if (len(headPointItems) == 0): return\n",
    "   \n",
    "    for headPointItem in headPointItems:\n",
    "        newPrefix = prefix.copy()\n",
    "        newPrefix.add(headPointItem)\n",
    "        support = headPointTable[headPointItem][0]\n",
    "        frequentPatterns[frozenset(newPrefix)] = support\n",
    "   \n",
    "        prefixPath = getPrefixPath(headPointTable, headPointItem)\n",
    "        if (prefixPath != {}):\n",
    "            conditionalFPtree, conditionalHeadPointTable = createFPTree(prefixPath, minSupport)\n",
    "            if conditionalHeadPointTable != None:\n",
    "                mineFPTree(conditionalHeadPointTable, newPrefix, frequentPatterns, minSupport)\n",
    "   \n",
    "   \n",
    "def getPrefixPath(headPointTable, headPointItem):\n",
    "    prefixPath = {}\n",
    "    beginNode = headPointTable[headPointItem][1]\n",
    "    prefixs = ascendTree(beginNode)\n",
    "    if ((prefixs != [])):\n",
    "        prefixPath[frozenset(prefixs)] = beginNode.count\n",
    "   \n",
    "    while (beginNode.nextSimilarItem != None):\n",
    "        beginNode = beginNode.nextSimilarItem\n",
    "        prefixs = ascendTree(beginNode)\n",
    "        if (prefixs != []):\n",
    "            prefixPath[frozenset(prefixs)] = beginNode.count\n",
    "   \n",
    "    return prefixPath\n",
    "   \n",
    "def ascendTree(treeNode):\n",
    "    prefixs = []\n",
    "    while ((treeNode.nodeParent != None) and (treeNode.nodeParent.nodeName != 'null')):\n",
    "        treeNode = treeNode.nodeParent\n",
    "        prefixs.append(treeNode.nodeName)\n",
    "   \n",
    "    return prefixs\n",
    "   \n",
    "def rulesGenerator(frequentPatterns, minConf, rules):\n",
    "    for frequentset in frequentPatterns:\n",
    "        if (len(frequentset) > 1):\n",
    "            getRules(frequentset, frequentset, rules, frequentPatterns, minConf)\n",
    "   \n",
    "   \n",
    "def removeStr(set, str):\n",
    "    tempSet = []\n",
    "    for elem in set:\n",
    "        if (elem != str):\n",
    "            tempSet.append(elem)\n",
    "    tempFrozenSet = frozenset(tempSet)\n",
    "   \n",
    "    return tempFrozenSet\n",
    "   \n",
    "def getRules(frequentset, currentset, rules, frequentPatterns, minConf):\n",
    "    for frequentElem in currentset:\n",
    "        subSet = removeStr(currentset, frequentElem)\n",
    "        confidence = frequentPatterns[frequentset] / frequentPatterns[subSet]\n",
    "        if (confidence >= minConf):\n",
    "            flag = False\n",
    "            for rule in rules:\n",
    "                if (rule[0] == subSet and rule[1] == frequentset - subSet):\n",
    "                    flag = True\n",
    "   \n",
    "            if (flag == False):\n",
    "                rules.append((subSet, frequentset - subSet, confidence))\n",
    "   \n",
    "            if (len(subSet) >= 2):\n",
    "                getRules(frequentset, subSet, rules, frequentPatterns, minConf)\n",
    "   \n",
    "   \n",
    "if __name__ == '__main__':\n",
    "    dataSet = loadDataSet()\n",
    "    frozenDataSet = transfer2FrozenDataSet(dataSet)\n",
    "    minSupport = 3\n",
    "    fptree, headPointTable = createFPTree(frozenDataSet, minSupport)\n",
    "    frequentPatterns = {}\n",
    "    prefix = set([])\n",
    "    mineFPTree(headPointTable, prefix, frequentPatterns, minSupport)\n",
    "    print(\"frequent patterns:\")\n",
    "    pprint.pprint(frequentPatterns)\n",
    "   \n",
    "    minConf = 0\n",
    "    rules = []\n",
    "    rulesGenerator(frequentPatterns, minConf, rules)\n",
    "    print(\"association rules:\")\n",
    "    pprint.pprint(rules)\n",
    "    print('rules num:', len(rules))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-06-12T02:29:15.626360Z",
     "start_time": "2020-06-12T02:29:15.621376Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'bread'})\n",
      "3\n",
      "frozenset({'bread', 'milk'})\n",
      "3\n",
      "frozenset({'eggs'})\n",
      "3\n",
      "frozenset({'bread', 'eggs'})\n",
      "3\n",
      "frozenset({'milk', 'eggs'})\n",
      "3\n",
      "frozenset({'bread', 'milk', 'eggs'})\n",
      "3\n",
      "frozenset({'shoes'})\n",
      "3\n",
      "frozenset({'socks', 'shoes'})\n",
      "3\n",
      "frozenset({'gloves'})\n",
      "3\n",
      "frozenset({'socks', 'gloves'})\n",
      "3\n",
      "frozenset({'milk'})\n",
      "4\n",
      "frozenset({'socks'})\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "for i in frequentPatterns:\n",
    "    print(i)\n",
    "    print(frequentPatterns[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
